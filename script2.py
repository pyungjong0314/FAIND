from fastapi import FastAPI
from fastapi.responses import FileResponse
import cv2
import datetime
import numpy as np
import os
from ultralytics import YOLO
from deep_sort_realtime.deepsort_tracker import DeepSort
from fastapi.staticfiles import StaticFiles

app = FastAPI()

# YOLOv8 ëª¨ë¸ ë° DeepSORT ì´ˆê¸°í™”
model = YOLO("yolov8n.pt")
tracker = DeepSort(max_age=50)

CONFIDENCE_THRESHOLD = 0.6
GREEN = (0, 255, 0)
WHITE = (255, 255, 255)
RED = (0, 0, 255)

# ì–¼êµ´ ê²€ì¶œ ëª¨ë¸ ë¡œë“œ (OpenCV Haar Cascade)
face_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + "haarcascade_frontalface_default.xml")

# ì €ì¥ëœ ì´ë¯¸ì§€ í´ë”
IMAGE_DIR = "images"
os.makedirs(IMAGE_DIR, exist_ok=True)

# ì…ì¶œì… ì„  ìœ„ì¹˜
OUTSIDE_LINE = None  # ì™¼ìª½ 1/3 ìœ„ì¹˜
INSIDE_LINE = None      # ì˜¤ë¥¸ìª½ 2/3 ìœ„ì¹˜

# ì´ë™ ë°©í–¥ íŒë³„ì„ ìœ„í•œ í´ë˜ìŠ¤
class Person:
    def __init__(self, track_id, first_location):
        self.track_id = track_id
        self.passed_lines = []  # "entrance" ë˜ëŠ” "exit" ê¸°ë¡
        self.direction = None   # "entry" ë˜ëŠ” "exit"
        self.first_location = first_location # ì²˜ìŒ ê°ì§€ëœ ìœ„ì¹˜
        self.items = set()

    def update_position(self, center_x):
        """í˜„ì¬ ì‚¬ëŒ ê°ì²´ê°€ ì–´ë–¤ ì„ ì„ í†µê³¼í–ˆëŠ”ì§€ ê¸°ë¡"""
        
        if self.first_location < OUTSIDE_LINE: # ì™¼ìª½ì—ì„œ ì²˜ìŒ ê°ì§€ë˜ì—ˆì„ ë•Œ
            if center_x > OUTSIDE_LINE and "outside" not in self.passed_lines:
                self.passed_lines.append("outside")
            elif center_x > INSIDE_LINE and "inside" not in self.passed_lines:
                self.passed_lines.append("inside")
        elif self.first_location > INSIDE_LINE: # ì˜¤ë¥¸ìª½ì—ì„œ ì²˜ìŒ ê°ì§€ë˜ì—ˆì„ ë•Œ
            if center_x > INSIDE_LINE and "inside" not in self.passed_lines:
                self.passed_lines.append("inside")
            elif center_x < OUTSIDE_LINE and "outside" not in self.passed_lines:
                self.passed_lines.append("outside")

        # ë‘ ê°œì˜ ê¸°ë¡ì´ ì¡´ì¬í•˜ë©´ ë°©í–¥ íŒë³„
        if len(self.passed_lines) >= 2:
            if self.passed_lines == ["inside", "outside"]:
                self.direction = "exit" # ì•ˆ -> ë°”ê¹¥ = í‡´ì¥
            elif self.passed_lines == ["outside", "inside"]:
                self.direction = "entry" # ë°”ê¹¥ -> ì•ˆ = ì…ì¥

# ëª¨ë“  ì‚¬ëŒ ê°ì²´ ì €ì¥ (track_id ê¸°ì¤€)
persons = {}

# ì´ë™ ë°©í–¥ì— ë”°ë¼ ì €ì¥í•  ì´ë¯¸ì§€ ë¦¬ìŠ¤íŠ¸
exit_persons = []
entry_persons = []

def apply_mosaic_to_head(image, xmin, ymin, xmax, ymax, mosaic_ratio=0.1):
    """ ì‚¬ëŒ ë°”ìš´ë”© ë°•ìŠ¤ì˜ ìƒë‹¨ì„ ë¨¸ë¦¬ë¡œ ê°„ì£¼í•˜ê³  ëª¨ìì´í¬ ì²˜ë¦¬ """
    head_height = int((ymax - ymin) * 0.3)  # ìƒë‹¨ 30%ë¥¼ ë¨¸ë¦¬ë¡œ ê°„ì£¼
    head_ymax = ymin + head_height

    head_region = image[ymin:head_ymax, xmin:xmax]
    if head_region.size == 0:
        return image  # ì˜ëª»ëœ ì˜ì—­ ë°©ì§€

    # ëª¨ìì´í¬ íš¨ê³¼ ì ìš©
    small = cv2.resize(head_region, (max(1, int((xmax - xmin) * mosaic_ratio)), max(1, int(head_height * mosaic_ratio))), interpolation=cv2.INTER_LINEAR)
    mosaic = cv2.resize(small, (xmax - xmin, head_height), interpolation=cv2.INTER_NEAREST)

    image[ymin:head_ymax, xmin:xmax] = mosaic
    return image

@app.get("/run-yolo")
def process_video():
    global OUTSIDE_LINE, INSIDE_LINE, persons, exit_persons, entry_persons

    video_cap = cv2.VideoCapture("test_video3.mp4")

    frame_count = 0

    # ì²« ë²ˆì§¸ í”„ë ˆì„ì—ì„œ ì˜ìƒ í¬ê¸° í™•ì¸í•˜ì—¬ ì„  ìœ„ì¹˜ ì„¤ì •
    ret, frame = video_cap.read()
    if not ret:
        return {"status": "Error: ì˜ìƒ íŒŒì¼ì„ ì½ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤."}

    frame_width = frame.shape[1]
    OUTSIDE_LINE = frame_width // 3       # 1/3 ì§€ì 
    INSIDE_LINE = (frame_width * 2) // 3     # 2/3 ì§€ì 

    while True:
        start = datetime.datetime.now() # FPS ì¸¡ì •ì„ ìœ„í•œ ì‹œê°„
        ret, frame = video_cap.read()
        if not ret:
            break

        frame_count += 1

        results = model(frame)[0]
        detections = [] # ì‚¬ëŒ ê°ì§€ë¥¼ ìœ„í•œ ë¦¬ìŠ¤íŠ¸íŠ¸
        detected_items = []  # ì†Œì§€í’ˆ ê°ì§€ë¥¼ ìœ„í•œ ë¦¬ìŠ¤íŠ¸
        
        for data in results.boxes.data.tolist():
            xmin, ymin, xmax, ymax, confidence, class_id = data
            if confidence < CONFIDENCE_THRESHOLD:
                continue
            class_name = results.names[class_id]
            
            width, height = xmax - xmin, ymax - ymin
            bbox = [xmin, ymin, width, height]
            
            if class_name == "person":
                detections.append((bbox, confidence, class_id))
            else:
                detected_items.append((class_name, bbox))  # ì†Œì§€í’ˆ ì €ì¥

        tracks = tracker.update_tracks(detections, frame=frame)

        for track in tracks:
            if not track.is_confirmed():
                continue

            track_id = track.track_id
            xmin, ymin, xmax, ymax = map(int, track.to_ltrb())
            center_x = (xmin + xmax) // 2

            if track_id not in persons:
                persons[track_id] = Person(track_id, center_x)

            person = persons[track_id]
            person.update_position(center_x)
            
            # **ì‚¬ëŒê³¼ ê²¹ì¹˜ëŠ” ì†Œì§€í’ˆ ì €ì¥**
            for item_name, (ixmin, iymin, ixmax, iymax) in detected_items:
                person.items.add(item_name)  # ì†Œì§€í’ˆ ì¶”ê°€
                # if (xmin < ixmin < xmax and ymin < iymin < ymax) or (xmin < ixmax < xmax and ymin < iymax < ymax):
                #     person.items.add(item_name)  # ì†Œì§€í’ˆ ì¶”ê°€

            # ì´ë™ ë°©í–¥ì´ íŠ¹ì •ëœ ê²½ìš°, ëª¨ìì´í¬ ì²˜ë¦¬ í›„ ì´ë¯¸ì§€ ì €ì¥
            if person.direction and person.direction not in person.passed_lines:
                frame_copy = frame.copy()

                # ì–¼êµ´ ê°ì§€ ë° ëª¨ìì´í¬ ì²˜ë¦¬
                gray_frame = cv2.cvtColor(frame_copy, cv2.COLOR_BGR2GRAY)
                faces = face_cascade.detectMultiScale(gray_frame, scaleFactor=1.1, minNeighbors=5, minSize=(30, 30))
                
                frame_copy = apply_mosaic_to_head(frame_copy, xmin, ymin, xmax, ymax)
                # ë°”ìš´ë”© ë°•ìŠ¤ ì˜ì—­ë§Œ í¬ë¡­ í›„ ì €ì¥
                person_crop = frame_copy[ymin:ymax, xmin:xmax]  # ë°”ìš´ë”© ë°•ìŠ¤ ì˜ì—­ ìë¥´ê¸°
                
                if person_crop.size != 0: # ë¹ˆ ì´ë¯¸ì§€ ë°©ì§€
                    filename = f"{person.direction}_{track_id}.jpg"
                    cv2.imwrite(f"images/{filename}", person_crop)

                if person.direction == "exit":
                    exit_persons.append({"image": filename, "items": list(person.items)})
                else:
                    entry_persons.append({"image": filename, "items": list(person.items)})

                person.passed_lines.append(person.direction) 

            # Bounding Box ê·¸ë¦¬ê¸°
            cv2.rectangle(frame, (xmin, ymin), (xmax, ymax), GREEN, 2)
            cv2.putText(frame, f"{track_id} - person", (xmin + 5, ymin - 8),
                        cv2.FONT_HERSHEY_SIMPLEX, 0.5, WHITE, 2)

        # ğŸ”¥ ë‘ ê°œì˜ ê°€ìƒì˜ ì„ ì„ ì˜ìƒì— í‘œì‹œ (ì…êµ¬/ì¶œêµ¬ ë¼ë²¨ ì¶”ê°€)
        cv2.line(frame, (OUTSIDE_LINE, 0), (OUTSIDE_LINE, frame.shape[0]), RED, 2)
        cv2.putText(frame, "outside line", (OUTSIDE_LINE - 40, 30),
                    cv2.FONT_HERSHEY_SIMPLEX, 0.8, RED, 2)

        cv2.line(frame, (INSIDE_LINE, 0), (INSIDE_LINE, frame.shape[0]), RED, 2)
        cv2.putText(frame, "inside line", (INSIDE_LINE - 20, 30),
                    cv2.FONT_HERSHEY_SIMPLEX, 0.8, RED, 2)
        
        
        end = datetime.datetime.now()
        fps = f"FPS: {1 / (end - start).total_seconds():.2f}"
        cv2.putText(frame, fps, (50, 50), cv2.FONT_HERSHEY_SIMPLEX, 2, (0, 0, 255), 8)
        
        cv2.imshow("YOLO Tracking", frame)
        if cv2.waitKey(1) & 0xFF == ord('q'):
            break


    video_cap.release()
    cv2.destroyAllWindows()

    return {
        "status": "YOLO ì‹¤í–‰ ì™„ë£Œ",
        "entry_person": entry_persons,
        "exit_person": exit_persons
    }


# FastAPIì— ì •ì  íŒŒì¼ ì„œë¹™ ì„¤ì •
app.mount("/images", StaticFiles(directory=IMAGE_DIR), name="images")

@app.get("/get-images")
def get_images():
    """ ì €ì¥ëœ ì…ì¶œì… ì´ë¯¸ì§€ ëª©ë¡ê³¼ ì†Œì§€í’ˆ ì •ë³´ë¥¼ ì œê³µí•˜ëŠ” API """
    return {
        "entry_persons": [
            {"image": f"http://127.0.0.1:8000/images/{person['image']}", "items": person["items"]}
            for person in entry_persons
        ],
        "exit_persons": [
            {"image": f"http://127.0.0.1:8000/images/{person['image']}", "items": person["items"]}
            for person in exit_persons
        ]
    }

import uvicorn

if __name__ == "__main__":
    uvicorn.run(app, host="0.0.0.0", port=8000)
